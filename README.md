# ğŸ³ RecipesNLP  
A Retrieval-Augmented Generation (RAG) system for recipe creation and title generation, powered by a fine-tuned **Mistral 7B** chatbot and a two-stage **retrieval & re-ranking pipeline**.

---

## ğŸš€ Project Overview  
This project addresses two key NLP challenges in the culinary domain:

- ğŸ” **Recipe Retrieval**: Find the most relevant recipes from a large corpus using hybrid search strategies  
- âœï¸ **Recipe Generation**: Generate structured, creative recipes under specific ingredient constraints (e.g., include/avoid)

A full **RAG pipeline** was implemented, combining retrieval, re-ranking, and fine-tuned language models.

---

## âš™ï¸ System Architecture  

### ğŸ”¹ 1. Two-Stage Retrieval  
Efficiently retrieves high-relevance recipe candidates from a large database.

**Stage 1 â€“ Candidate Retrieval**  
- ğŸ§  Lexical: **TF-IDF**  
- ğŸ” Semantic: **KNN** over sentence embeddings

**Stage 2 â€“ Re-ranking**  
- ğŸ“ **Cosine Similarity** (multi-qa-MiniLM-L6-cos-v1)  
- ğŸ¤ **Cross-Encoder** (cross-encoder/ms-marco-MiniLM-L-6-v2)

**Evaluation**  
- ğŸ§ª Test set built with LLM + human feedback  
- ğŸ“Š Metric: **Spearman's Ï** for ranking quality  
- âœ… **TF-IDF + Cross-Encoder** delivered the best balance of recall and precision

---

### ğŸ”¹ 2. Fine-Tuned Language Models  

#### ğŸ·ï¸ Title Generation  
Input: recipe procedure â†’ Output: title  
Best result: `FLAN-T5-base` trained on 6k samples (concise + creative)

#### ğŸ§¾ Recipe Generation  
Input: ingredients to include/exclude â†’ Output: full recipe (Title, Ingredients, Instructions)

**Models evaluated**:  
- `FLAN-T5-small/base`  
- `Mistral-7B-Instruct-v0.3`

**Prompting strategies (for Mistral-7B):**  
1. Standard instruction following  
2. Simple persona-based prompt  
3. Detailed system prompt (structured output enforced)

---

### ğŸ”¹ 3. RAG-Powered Recipe Generation  
The final system integrates retrieval + generation:

1. ğŸ” Retrieve top 3 most relevant recipes  
2. ğŸ§  Feed them as context to **fine-tuned Mistral-7B**  
3. âœ¨ Generate new, constraint-aware recipes with improved coherence and creativity

---

## ğŸ“ˆ Results & Key Findings  

### ğŸ§ª Retrieval  
- âœ… **TF-IDF + Cross-Encoder** = most effective pipeline  
- âš ï¸ KNN alone = weaker performance on keyword-driven queries  

### ğŸ§  Fine-Tuning â€“ Title Generation  
| Model         | Dataset Size | Quality     |
|---------------|--------------|-------------|
| FLAN-T5-base  | 6k           | â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸ (Best) |
| Mistral-7B    | 6k           | Overkill, too verbose |

### ğŸ§  Fine-Tuning â€“ Recipe Generation  
| Model + Setup                           | Constraint Adherence | Creativity | Structure |
|----------------------------------------|----------------------|------------|-----------|
| Mistral-7B (Base)                       | âŒ Often violated     | âœ…         | âš ï¸ Loose   |
| Mistral-7B (Fine-tuned + Prompt + RAG) | âœ… Always respected   | âœ…    | âœ… Structured |

### ğŸ§‘â€âš–ï¸ LLM Evaluation (Gemini 2.5 Pro)  
| Query                                   | Best Model                        | Avg Score (10) |
|----------------------------------------|-----------------------------------|----------------|
| `pasta and banana`                     | Mistral-7B (FT + RAG)             | 9.5            |
| `pasta and banana, no nuts/oranges`   | Mistral-7B (FT + RAG)             | 9.0            |
| `rice, coconut milk, chicken, no peppers/wine` | Mistral-7B (FT + RAG)     | 9.8            |


